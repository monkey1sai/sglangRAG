"""
ç¬¦è™Ÿå›æ­¸æ•´åˆæ¸¬è©¦ - é©—è­‰ SAGA å¤šè¼ªç›®æ¨™æ¼”åŒ–

éš±è—å…¬å¼: y = xÂ² + 3x - 2
ç›®æ¨™: è®“ SAGA é€éå¤šè¼ªè¿­ä»£ã€Œç™¼ç¾ã€é€™å€‹å…¬å¼

è©•åˆ†ç¶­åº¦:
1. æ“¬åˆç²¾åº¦ (50%) - MSE è¶Šå°åˆ†æ•¸è¶Šé«˜
2. å…¬å¼ç°¡æ½”æ€§ (30%) - å­—ç¬¦æ•¸è¶Šå°‘åˆ†æ•¸è¶Šé«˜  
3. æ³›åŒ–èƒ½åŠ› (20%) - æ¸¬è©¦é»é æ¸¬æº–ç¢ºåº¦
"""
from __future__ import annotations

import asyncio
import logging
import sys
from pathlib import Path

# æ·»åŠ å°ˆæ¡ˆæ ¹ç›®éŒ„åˆ° Python è·¯å¾‘
sys.path.insert(0, str(Path(__file__).parent.parent))

from saga.config import SagaConfig
from saga.outer_loop import OuterLoop, LoopState, IterationResult, FinalReport, HumanReviewRequest
from saga.mode_controller import ModeController, OperationMode
from saga.termination import TerminationChecker, TerminationConfig
from saga.modules.advanced_analyzer import AdvancedAnalyzer
from saga.modules.advanced_planner import AdvancedPlanner
from saga.modules.advanced_implementer import AdvancedImplementer
from saga.modules.advanced_optimizer import AdvancedOptimizer
from saga.search.generators import LLMGenerator, EvoGenerator
from saga.adapters.sglang_adapter import SGLangAdapter

# è¨­å®š logging
logging.basicConfig(
    level=logging.INFO,
    format="%(asctime)s [%(levelname)s] %(message)s"
)
logger = logging.getLogger(__name__)

# =============================================================================
# æ¸¬è©¦æ•¸æ“š
# =============================================================================

# éš±è—å…¬å¼: y = xÂ² + 3x - 2
TRUE_FORMULA = "x**2 + 3*x - 2"

DATA_POINTS = [
    (-3, -2),   # (-3)Â² + 3*(-3) - 2 = 9 - 9 - 2 = -2
    (-2, -4),   # (-2)Â² + 3*(-2) - 2 = 4 - 6 - 2 = -4
    (-1, -4),   # (-1)Â² + 3*(-1) - 2 = 1 - 3 - 2 = -4
    (0, -2),    # 0Â² + 3*0 - 2 = -2
    (1, 2),     # 1Â² + 3*1 - 2 = 1 + 3 - 2 = 2
    (2, 8),     # 2Â² + 3*2 - 2 = 4 + 6 - 2 = 8
    (3, 16),    # 3Â² + 3*3 - 2 = 9 + 9 - 2 = 16
    (4, 26),    # 4Â² + 3*4 - 2 = 16 + 12 - 2 = 26
]

# æ³›åŒ–æ¸¬è©¦é»
TEST_X = 5
TEST_Y = 38  # 5Â² + 3*5 - 2 = 25 + 15 - 2 = 38

# åˆå§‹å€™é¸çŒœæ¸¬ (åˆ»æ„é¸æ“‡è¼ƒå·®çš„å…¬å¼)
INITIAL_CANDIDATES = [
    "2*x",           # ç·šæ€§ï¼Œæ“¬åˆå·®
    "x + 1",         # ç·šæ€§ï¼Œæ“¬åˆå·®
    "3*x - 1",       # ç·šæ€§ï¼Œæ“¬åˆè¼ƒå·®
    "x*x",           # ç¼ºå°‘ç·šæ€§é …å’Œå¸¸æ•¸é …
    "x*x + x",       # ç¼ºå°‘ä¿‚æ•¸èª¿æ•´
]


# =============================================================================
# è©•åˆ†å‡½æ•¸
# =============================================================================

def safe_eval_formula(formula: str, x: float) -> float:
    """å®‰å…¨åŸ·è¡Œå…¬å¼è¨ˆç®—"""
    try:
        # ç§»é™¤å¯èƒ½çš„ç©ºç™½å’Œå±éšªå­—ç¬¦
        clean_formula = formula.strip()
        # åªå…è¨±åŸºæœ¬æ•¸å­¸é‹ç®—
        allowed = {"x": x, "__builtins__": {}}
        return float(eval(clean_formula, allowed))
    except Exception:
        return float('inf')


def calculate_mse(formula: str, data_points: list) -> float:
    """è¨ˆç®—å‡æ–¹èª¤å·®"""
    if not data_points:
        return float('inf')
    
    errors = []
    for x, y_true in data_points:
        y_pred = safe_eval_formula(formula, x)
        if y_pred == float('inf'):
            return float('inf')
        errors.append((y_pred - y_true) ** 2)
    
    return sum(errors) / len(errors)


def score_formula(formula: str, context: dict = None) -> list:
    """è©•åˆ†å‡½æ•¸ï¼šæ“¬åˆç²¾åº¦ã€ç°¡æ½”æ€§ã€æ³›åŒ–èƒ½åŠ›
    
    Args:
        formula: å€™é¸å…¬å¼å­—ä¸²
        context: åŒ…å« data_points, test_x, test_y çš„ä¸Šä¸‹æ–‡
        
    Returns:
        [fit_score, simplicity_score, generalization_score]
    """
    context = context or {}
    data_points = context.get("data_points", DATA_POINTS)
    test_x = context.get("test_x", TEST_X)
    test_y = context.get("test_y", TEST_Y)
    
    # 1. æ“¬åˆç²¾åº¦ (æ¬Šé‡ 0.5)
    mse = calculate_mse(formula, data_points)
    if mse == float('inf'):
        fit_score = 0.0
    else:
        # ä½¿ç”¨ sigmoid å‡½æ•¸å°‡ MSE æ˜ å°„åˆ° [0, 1]
        # MSE=0 â†’ score=1, MSE=100 â†’ scoreâ‰ˆ0
        fit_score = max(0, 1 - mse / 100)
    
    # 2. ç°¡æ½”æ€§ (æ¬Šé‡ 0.3)
    formula_len = len(formula.strip())
    # å‡è¨­æœ€å„ªå…¬å¼é•·åº¦ç´„ 15 å­—ç¬¦ (x**2 + 3*x - 2)
    simplicity_score = max(0, 1 - formula_len / 50)
    
    # 3. æ³›åŒ–èƒ½åŠ› (æ¬Šé‡ 0.2)
    y_pred_test = safe_eval_formula(formula, test_x)
    if y_pred_test == float('inf'):
        generalization_score = 0.0
    else:
        gen_error = abs(y_pred_test - test_y)
        generalization_score = max(0, 1 - gen_error / 50)
    
    return [fit_score, simplicity_score, generalization_score]


# =============================================================================
# ç”Ÿæˆè©•åˆ†ç¨‹å¼ç¢¼ (å‹•æ…‹ç”Ÿæˆçµ¦ sandbox åŸ·è¡Œ)
# =============================================================================

SCORING_CODE = '''
def score(text: str, context: dict) -> list:
    """è©•åˆ†å‡½æ•¸ï¼šæ“¬åˆç²¾åº¦ã€ç°¡æ½”æ€§ã€æ³›åŒ–èƒ½åŠ›"""
    import math
    
    formula = text.strip()
    data_points = context.get("data_points", [])
    test_x = context.get("test_x", 5)
    test_y = context.get("test_y", 38)
    
    def safe_eval(f, x):
        try:
            return float(eval(f, {"x": x, "math": math, "__builtins__": {}}))
        except:
            return float('inf')
    
    # 1. æ“¬åˆç²¾åº¦
    mse = 0
    for x, y_true in data_points:
        y_pred = safe_eval(formula, x)
        if y_pred == float('inf'):
            mse = 100
            break
        mse += (y_pred - y_true) ** 2
    mse /= max(len(data_points), 1)
    fit_score = max(0, 1 - mse / 100)
    
    # 2. ç°¡æ½”æ€§
    simplicity_score = max(0, 1 - len(formula) / 50)
    
    # 3. æ³›åŒ–èƒ½åŠ›
    y_pred_test = safe_eval(formula, test_x)
    if y_pred_test == float('inf'):
        gen_score = 0.0
    else:
        gen_score = max(0, 1 - abs(y_pred_test - test_y) / 50)
    
    return [fit_score, simplicity_score, gen_score]
'''


# =============================================================================
# ä¸»æ¸¬è©¦æµç¨‹
# =============================================================================

async def run_symbolic_regression_test():
    """åŸ·è¡Œç¬¦è™Ÿå›æ­¸æ•´åˆæ¸¬è©¦"""
    
    print("=" * 60)
    print("  ç¬¦è™Ÿå›æ­¸æ•´åˆæ¸¬è©¦ - SAGA å¤šè¼ªç›®æ¨™æ¼”åŒ–é©—è­‰")
    print("=" * 60)
    print()
    print(f"ğŸ¯ éš±è—å…¬å¼: {TRUE_FORMULA}")
    print(f"ğŸ“Š æ¸¬è©¦æ•¸æ“š: {len(DATA_POINTS)} å€‹é»")
    print(f"ğŸ”¬ æ³›åŒ–æ¸¬è©¦: x={TEST_X} â†’ y={TEST_Y}")
    print()
    
    # é…ç½®
    config = SagaConfig(
        use_sglang=True,
        use_llm_modules=True,
        beam_width=5,
    )
    
    # åˆå§‹åŒ–æ¨¡çµ„
    mode = ModeController(OperationMode.AUTOPILOT)  # å…¨è‡ªå‹•åŸ·è¡Œ
    
    terminator = TerminationChecker(TerminationConfig(
        max_iters=5,
        convergence_eps=0.01,
        convergence_patience=2,
        goal_thresholds={
            "goal_0": 0.95,  # æ“¬åˆç²¾åº¦é–¾å€¼
            "goal_1": 0.5,   # ç°¡æ½”æ€§é–¾å€¼
            "goal_2": 0.9,   # æ³›åŒ–èƒ½åŠ›é–¾å€¼
        }
    ))
    
    analyzer = AdvancedAnalyzer(config={
        "goal_thresholds": {
            "goal_0": 0.95,
            "goal_1": 0.5,
            "goal_2": 0.9,
        },
        "bottleneck_threshold": 0.5
    })
    
    planner = AdvancedPlanner()
    implementer = AdvancedImplementer()
    
    # åˆå§‹åŒ– SGLang é©é…å™¨
    sglang_url = config.sglang_url or "http://localhost:8082/v1/chat/completions"
    sglang_api_key = config.sglang_api_key or ""
    
    print(f"ğŸ”— SGLang URL: {sglang_url}")
    
    try:
        sglang_client = SGLangAdapter(base_url=sglang_url, api_key=sglang_api_key)
        # ä½¿ç”¨ LLM é©…å‹•çš„ç”Ÿæˆå™¨
        generator = LLMGenerator(client=sglang_client)
        print("âœ… ä½¿ç”¨ LLM é©…å‹•çš„å€™é¸ç”Ÿæˆå™¨")
    except Exception as e:
        logger.warning(f"ç„¡æ³•åˆå§‹åŒ– LLMGenerator: {e}ï¼Œæ”¹ç”¨ EvoGenerator")
        generator = EvoGenerator(mutation_rate=0.3, crossover_rate=0.5)
        print("âš ï¸ ä½¿ç”¨é€²åŒ–ç®—æ³•ç”Ÿæˆå™¨ (Fallback)")
    
    optimizer = AdvancedOptimizer(
        generator=generator,
        config={
            "inner_iterations": 3,
            "batch_size": 8,
            "timeout": 10.0  # LLM éœ€è¦è¼ƒé•·çš„è¶…æ™‚æ™‚é–“
        }
    )
    
    # åˆå§‹ç‹€æ…‹
    initial_state = LoopState(
        text=f"æ‰¾å‡ºæ“¬åˆä»¥ä¸‹æ•¸æ“šé»çš„æ•¸å­¸å…¬å¼: {DATA_POINTS}",
        keywords=["xÂ²", "å¤šé …å¼", "æ“¬åˆ", "äºŒæ¬¡"],
        constraints=[
            "å…¬å¼å¿…é ˆæ˜¯ x çš„å‡½æ•¸",
            "ä½¿ç”¨ Python èªæ³• (ä¾‹å¦‚ x**2 è€Œé x^2)",
        ],
        candidates=INITIAL_CANDIDATES.copy(),
        weights=[0.5, 0.3, 0.2],  # æ“¬åˆã€ç°¡æ½”ã€æ³›åŒ–
        goal_thresholds={
            "goal_0": 0.95,
            "goal_1": 0.5,
            "goal_2": 0.9,
        }
    )
    
    # åŸ·è¡Œå¤–å±¤è¿´åœˆ
    loop = OuterLoop(
        config=config,
        analyzer=analyzer,
        planner=planner,
        implementer=implementer,
        optimizer=optimizer,
        terminator=terminator,
        mode_controller=mode
    )
    
    print("-" * 60)
    print("é–‹å§‹å¤šè¼ªè¿­ä»£...")
    print("-" * 60)
    print()
    
    iteration_results = []
    final_report = None
    all_reports = []  # è¨˜éŒ„æ‰€æœ‰è¼ªæ¬¡çš„è©³ç´°å ±å‘Š
    
    import json
    from datetime import datetime
    
    async for result in loop.run(initial_state, run_id="symbolic_regression_test"):
        if isinstance(result, IterationResult):
            iteration_results.append(result)
            
            # è¨ˆç®—è©³ç´°è©•åˆ†
            scores = score_formula(result.best_candidate, {
                "data_points": DATA_POINTS,
                "test_x": TEST_X,
                "test_y": TEST_Y
            })
            
            # å»ºç«‹è©³ç´°å ±å‘Š
            round_report = {
                "iteration": result.iteration,
                "timestamp": datetime.now().isoformat(),
                "best_candidate": result.best_candidate,
                "best_score": result.best_score,
                "scores": {
                    "fit_accuracy": scores[0],
                    "simplicity": scores[1],
                    "generalization": scores[2]
                },
                "analysis": {
                    "bottleneck": result.analysis_report.bottleneck,
                    "pareto_count": result.analysis_report.pareto_count,
                    "improvement_trend": result.analysis_report.improvement_trend,
                    "suggested_constraints": result.analysis_report.suggested_constraints
                },
                "new_constraints": result.new_constraints,
                "elapsed_ms": result.elapsed_ms
            }
            all_reports.append(round_report)
            
            # è¼¸å‡ºè©³ç´°å ±å‘Š
            print("=" * 60)
            print(f"ğŸ“ Iteration {result.iteration} è©³ç´°å ±å‘Š")
            print("=" * 60)
            print(f"â±ï¸  æ™‚é–“æˆ³: {round_report['timestamp']}")
            print(f"â±ï¸  è€—æ™‚: {result.elapsed_ms} ms")
            print()
            print(f"ğŸ† æœ€ä½³å€™é¸: {result.best_candidate}")
            print(f"ğŸ“Š åŠ æ¬Šç¸½åˆ†: {result.best_score:.4f}")
            print()
            print("ğŸ“ˆ è©³ç´°è©•åˆ†:")
            print(f"   æ“¬åˆç²¾åº¦: {scores[0]:.4f} (æ¬Šé‡ 50%)")
            print(f"   å…¬å¼ç°¡æ½”: {scores[1]:.4f} (æ¬Šé‡ 30%)")
            print(f"   æ³›åŒ–èƒ½åŠ›: {scores[2]:.4f} (æ¬Šé‡ 20%)")
            print()
            print("ğŸ” åˆ†æçµæœ:")
            print(f"   ç“¶é ¸ç›®æ¨™: {result.analysis_report.bottleneck}")
            print(f"   Pareto æ•¸é‡: {result.analysis_report.pareto_count}")
            print(f"   æ”¹å–„è¶¨å‹¢: {result.analysis_report.improvement_trend:+.2%}")
            
            if result.analysis_report.suggested_constraints:
                print(f"   å»ºè­°ç´„æŸ: {result.analysis_report.suggested_constraints}")
            
            if result.new_constraints:
                print()
                print("ğŸ†• æ–°å¢ç´„æŸ:")
                for c in result.new_constraints:
                    print(f"   â€¢ {c}")
            
            print()
            print("-" * 60)
            print()
            
        elif isinstance(result, HumanReviewRequest):
            print(f"â¸ï¸  éœ€è¦äººå·¥å¯©æ ¸: {result.message}")
            # åœ¨ Autopilot æ¨¡å¼ä¸‹ä¸æ‡‰è©²å‡ºç¾
            
        elif isinstance(result, FinalReport):
            final_report = result
    
    # è¼¸å‡ºæœ€çµ‚çµæœ
    print("=" * 60)
    print("  æ¸¬è©¦çµæœ")
    print("=" * 60)
    print()
    
    if final_report:
        print(f"âœ… çµ‚æ­¢åŸå› : {final_report.termination_reason}")
        print(f"ğŸ“Š ç¸½è¿­ä»£æ•¸: {final_report.total_iterations}")
        print(f"ğŸ† æœ€çµ‚æœ€ä½³å€™é¸: {final_report.best_candidate}")
        print(f"ğŸ“ˆ æœ€çµ‚åˆ†æ•¸: {final_report.best_score:.4f}")
        print(f"â±ï¸ ç¸½è€—æ™‚: {final_report.elapsed_ms} ms")
        print()
        
        # é©—è­‰æœ€çµ‚å…¬å¼
        print("ğŸ“ å…¬å¼é©—è­‰:")
        final_formula = final_report.best_candidate
        for x, y_true in DATA_POINTS:
            y_pred = safe_eval_formula(final_formula, x)
            status = "âœ“" if abs(y_pred - y_true) < 0.01 else "âœ—"
            print(f"   x={x:2d}: é æ¸¬={y_pred:6.2f}, çœŸå¯¦={y_true:6.2f} {status}")
        
        # æ³›åŒ–æ¸¬è©¦
        y_pred_test = safe_eval_formula(final_formula, TEST_X)
        gen_status = "âœ“" if abs(y_pred_test - TEST_Y) < 1 else "âœ—"
        print()
        print(f"ğŸ”¬ æ³›åŒ–æ¸¬è©¦: x={TEST_X} â†’ é æ¸¬={y_pred_test:.2f}, çœŸå¯¦={TEST_Y} {gen_status}")
        
        # èˆ‡çœŸå¯¦å…¬å¼æ¯”è¼ƒ
        print()
        print(f"ğŸ¯ çœŸå¯¦å…¬å¼: {TRUE_FORMULA}")
        print(f"ğŸ¤– ç™¼ç¾å…¬å¼: {final_formula}")
        
        # åˆ¤æ–·æˆåŠŸèˆ‡å¦
        final_scores = score_formula(final_formula, {
            "data_points": DATA_POINTS,
            "test_x": TEST_X,
            "test_y": TEST_Y
        })
        
        print()
        if final_scores[0] >= 0.95 and final_scores[2] >= 0.9:
            print("ğŸ‰ æ¸¬è©¦æˆåŠŸï¼SAGA æˆåŠŸç™¼ç¾äº†å…¬å¼ï¼")
        else:
            print("âš ï¸ æ¸¬è©¦éƒ¨åˆ†æˆåŠŸï¼Œå…¬å¼æ¥è¿‘ä½†ä¸å®Œå…¨åŒ¹é…")
            print(f"   æ“¬åˆç²¾åº¦: {final_scores[0]:.3f} (éœ€è¦ â‰¥ 0.95)")
            print(f"   æ³›åŒ–èƒ½åŠ›: {final_scores[2]:.3f} (éœ€è¦ â‰¥ 0.90)")
    else:
        print("âŒ æ¸¬è©¦å¤±æ•—ï¼šæœªç²å¾—æœ€çµ‚å ±å‘Š")
    
    return final_report


# =============================================================================
# ç°¡åŒ–ç‰ˆæ¸¬è©¦ (ä¸ä¾è³´å®Œæ•´ OuterLoop)
# =============================================================================

def run_simple_test():
    """ç°¡åŒ–ç‰ˆæ¸¬è©¦ - ç›´æ¥æ¸¬è©¦è©•åˆ†å‡½æ•¸å’Œæ¼”åŒ–é‚è¼¯"""
    
    print("=" * 60)
    print("  ç°¡åŒ–ç‰ˆç¬¦è™Ÿå›æ­¸æ¸¬è©¦")
    print("=" * 60)
    print()
    
    # æ¸¬è©¦è©•åˆ†å‡½æ•¸
    print("ğŸ“Š è©•åˆ†å‡½æ•¸æ¸¬è©¦:")
    test_formulas = [
        "2*x",                # ç·šæ€§
        "x**2",               # ç¼ºå°‘ç·šæ€§é …
        "x**2 + 3*x",         # ç¼ºå°‘å¸¸æ•¸é …
        "x**2 + 3*x - 2",     # æ­£ç¢ºç­”æ¡ˆ
        "x**2 + 3*x - 1.5",   # æ¥è¿‘æ­£ç¢º
    ]
    
    context = {
        "data_points": DATA_POINTS,
        "test_x": TEST_X,
        "test_y": TEST_Y
    }
    
    best_formula = None
    best_total_score = 0
    weights = [0.5, 0.3, 0.2]
    
    for formula in test_formulas:
        scores = score_formula(formula, context)
        total = sum(w * s for w, s in zip(weights, scores))
        mse = calculate_mse(formula, DATA_POINTS)
        
        print(f"  {formula:20s} | MSE={mse:8.2f} | æ“¬åˆ={scores[0]:.3f} | ç°¡æ½”={scores[1]:.3f} | æ³›åŒ–={scores[2]:.3f} | ç¸½åˆ†={total:.3f}")
        
        if total > best_total_score:
            best_total_score = total
            best_formula = formula
    
    print()
    print(f"ğŸ† æœ€ä½³å…¬å¼: {best_formula}")
    print(f"   ç¸½åˆ†: {best_total_score:.3f}")
    
    # é©—è­‰
    print()
    print("ğŸ“ é©—è­‰æœ€ä½³å…¬å¼:")
    for x, y_true in DATA_POINTS[:4]:
        y_pred = safe_eval_formula(best_formula, x)
        print(f"   x={x:2d}: é æ¸¬={y_pred:6.2f}, çœŸå¯¦={y_true:6.2f}")


if __name__ == "__main__":
    import argparse
    
    parser = argparse.ArgumentParser(description="ç¬¦è™Ÿå›æ­¸æ•´åˆæ¸¬è©¦")
    parser.add_argument("--simple", action="store_true", help="åŸ·è¡Œç°¡åŒ–ç‰ˆæ¸¬è©¦")
    args = parser.parse_args()
    
    if args.simple:
        run_simple_test()
    else:
        # åŸ·è¡Œå®Œæ•´ç•°æ­¥æ¸¬è©¦
        asyncio.run(run_symbolic_regression_test())
